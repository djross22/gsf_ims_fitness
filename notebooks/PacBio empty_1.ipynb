{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.Seq import Seq\n",
    "from Bio.Alphabet import generic_dna\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "import gsf_ims_fitness as fitness\n",
    "\n",
    "import pickle\n",
    "\n",
    "import gzip\n",
    "\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "#from sklearn.mixture import GaussianMixture\n",
    "#from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%autosave 0\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\", {'xtick.direction':'in', 'xtick.top':True, 'ytick.direction':'in', 'ytick.right':True})\n",
    "\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "\n",
    "plt.rcParams['legend.fontsize'] = 14\n",
    "plt.rcParams['legend.edgecolor'] = 'k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_directory = os.getcwd()\n",
    "notebook_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'output_file_label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = notebook_directory + \"\\\\barcode_analysis\"\n",
    "os.chdir(data_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob.glob(\"*reverse_barcode*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_barcode_map_file = glob.glob(\"*reverse_barcode*.csv\")[0]\n",
    "reverse_barcode_map_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rev_barcode_clusterID_frame = pd.read_csv(reverse_barcode_map_file, skipinitialspace=True)\n",
    "rev_barcode_clusterID_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_barcode_center_file = glob.glob(\"*reverse_cluster*.csv\")[0]\n",
    "reverse_barcode_center_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rev_barcode_center_frame = pd.read_csv(reverse_barcode_center_file, skipinitialspace=True)\n",
    "rev_barcode_center_frame.rename(columns={\"time_point_1\": \"HiSeq_count\"}, inplace=True)\n",
    "rev_barcode_center_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_barcode_center_frame.sort_values(by=['HiSeq_count'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rev_barcode_clusterID_dict = dict(zip(rev_barcode_clusterID_frame[\"Unique.reads\"], rev_barcode_clusterID_frame[\"Cluster.ID\"]))\n",
    "\n",
    "for index, row in rev_barcode_center_frame.iterrows():\n",
    "    rev_barcode_clusterID_dict[row[\"Center\"]] = row[\"Cluster.ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_barcode_map_file = glob.glob(\"*forward_barcode*.csv\")[0]\n",
    "forward_barcode_map_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_barcode_clusterID_frame = pd.read_csv(forward_barcode_map_file, skipinitialspace=True)\n",
    "for_barcode_clusterID_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_barcode_center_file = glob.glob(\"*forward_cluster*.csv\")[0]\n",
    "forward_barcode_center_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for_barcode_center_frame = pd.read_csv(forward_barcode_center_file, skipinitialspace=True)\n",
    "for_barcode_center_frame.rename(columns={\"time_point_1\": \"HiSeq_count\"}, inplace=True)\n",
    "for_barcode_center_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_barcode_center_frame.sort_values(by=['HiSeq_count'], ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_barcode_clusterID_dict = dict(zip(for_barcode_clusterID_frame[\"Unique.reads\"], for_barcode_clusterID_frame[\"Cluster.ID\"]))\n",
    "\n",
    "for index, row in for_barcode_center_frame.iterrows():\n",
    "    for_barcode_clusterID_dict[row[\"Center\"]] = row[\"Cluster.ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebook_directory)\n",
    "glob.glob(\"*pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebook_directory)\n",
    "pickle_file = experiment + '_BarSeqFitnessFrame.pkl'\n",
    "print(pickle_file)\n",
    "\n",
    "barcode_frame = pickle.load(open(pickle_file, 'rb'))\n",
    "\n",
    "hiseq_count_frame = barcode_frame.barcode_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hiseq_count_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiseq_count_frame[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"empty_1\"\n",
    "\n",
    "wild_type_dict = {}\n",
    "trim_dict = {}\n",
    "wild_type_dict[\"empty_1\"] = \"CTAGCGCTGAGGTCTGCCTCGTGCAGCGAGTCAGTGAGCGAGGAAGCACCTCAGATAAAATATTTGCTCATGAGCCCGAAGTGGCGAGCCCGACAAAAAACCCCTCAAGACCCGTTTAGAGGCCCCAAGGGGTTATGCTAGTCTTCCCCATCGGTGAGCCCGGGCTGTCGGCGT\"\n",
    "trim_dict[\"empty_1\"] = 25\n",
    "wild_type_dict[\"empty_2\"] = \"CGGTGGCCCGGGCGGCCGCACGATGCGTCCGGCGTAGAGGATCTGCTCATGTTTGACAGCTTATCATCGATGCATAATGTGCCTGTCAAATGGACGAAGCAGGGATTCTGCAAACCCTATGCTACTCCCTCGAGCCGTCAATTGTCTGATTCGTTACCAATTATTTTTTCCTCCTGGATTA\"\n",
    "trim_dict[\"empty_2\"] = 25\n",
    "wild_type_dict[\"insulator\"] = \"ATTCACCACCCTGAATTGACTCTCTTCCGGGCGCTATCATGCCATACCGCGAAAGGTTTTGCGCCATTCGATGGCGCGCCGCCATAAATCTCGGTACCAAATTCCAGAAAAGAGGCCTCCCGAAAGGGGGGCCTTTTTTCGTTTTGGTCCGAGCTGTTGACAATTAATCATCGGCTCGTATAATGTGTGGAATTGTGAGCGGATAACAATTAGCTGTCACCGGATGTGCTTTCCGGTCTGATGAGTCCGTGAGGACGAAACAGCCTCTACAAATAATTTTGTTTAATACTAGCCATCAAGGAGAGCTGCTAC\"\n",
    "trim_dict[\"insulator\"] = 25\n",
    "wild_type_dict[\"KAN\"] = \"AAGCGGGAGACCAGAAACAAAAAAAGGCCCCCCGTTAGGGAGGCCTTCAATAATTGGTTGTGTCTCAAAATCTCTGATGTACATTGCACAAGATAAAAATATATCATCATGAACAATAAAACTGTCTGCTTACATAAACAGTAATACAAGGGGTGTTATGAGCCATATTCAACGGGAAACGTCTTGCTCCAGGCCGCGATTAAATTCCAACATGGATGCTGATTTATATGGGTATAAATGGGCTCGCGATAATGTCGGGCAATCAGGTGCGACAATCTATCGATTGTATGGGAAGCCCGATGCGCCAGAGTTGTTTCTGAAACATGGCAAAGGTAGCGTTGCCAATGATGTTACAGATGAGATGGTCAGACTAAACTGGCTGACGGAATTTATGCCTCTTCCGACCATCAAGCATTTTATCCGTACTCCTGATGATGCATGGTTACTCACCACTGCGATCCCCGGGAAAACAGCATTCCAGGTATTAGAAGAATATCCTGATTCAGGTGAAAATATTGTTGATGCGCTGGCAGTGTTCCTGCGCCGGTTGCATTCGATTCCTGTTTGTAATTGTCCTTTTAACAGCGATCGCGTATTTCGTCTCGCTCAGGCGCAATCACGAATGAATAACGGTTTGGTTGATGCGAGTGATTTTGATGACGAGCGTAATGGCTGGCCTGTTGAACAAGTCTGGAAAGAAATGCATAAGCTTTTGCCATTCTCACCGGATTCAGTCGTCACTCATGGTGATTTCTCACTTGATAACCTTATTTTTGACGAGGGGAAATTAATAGGTTGTATTGATGTTGGACGAGTCGGAATCGCAGACCGATACCAGGATCTTGCCATCCTATGGAACTGCCTCGGTGAGTTTTCTCCTTCATTACAGAAACGGCTTTTTCAAAAATATGGTATTGATAATCCTGATATGAATAAATTGCAGTTTCATTTGATGCTCGATGAGTTTTTCTAAGGTAACTGTCAGACCAAGTTTACTCATATATACTTTAGATTGATTTTTCGTTCCACTGAGCGTCAGACCCC\"\n",
    "trim_dict[\"KAN\"] = 0\n",
    "wild_type_dict[\"lacI\"] = \"TCACTGCCCGCTTTCCAGTCGGGAAACCTGTCGTGCCAGCTGCATTAATGAATCGGCCAACGCGCGGGGAGAGGCGGTTTGCGTATTGGGCGCCAGGGTGGTTTTTCTTTTCACCAGTGAGACTGGCAACAGCTGATTGCCCTTCACCGCCTGGCCCTGAGAGAGTTGCAGCAAGCGGTCCACGCTGGTTTGCCCCAGCAGGCGAAAATCCTGTTTGATGGTGGTTAACGGCGGGATATAACATGAGCTATCTTCGGTATCGTCGTATCCCACTACCGAGATATCCGCACCAACGCGCAGCCCGGACTCGGTAATGGCGCGCATTGCGCCCAGCGCCATCTGATCGTTGGCAACCAGCATCGCAGTGGGAACGATGCCCTCATTCAGCATTTGCATGGTTTGTTGAAAACCGGACATGGCACTCCAGTCGCCTTCCCGTTCCGCTATCGGCTGAATTTGATTGCGAGTGAGATATTTATGCCAGCCAGCCAGACGCAGACGCGCCGAGACAGAACTTAATGGGCCCGCTAACAGCGCGATTTGCTGGTGACCCAATGCGACCAGATGCTCCACGCCCAGTCGCGTACCGTCCTCATGGGAGAAAATAATACTGTTGATGGGTGTCTGGTCAGAGACATCAAGAAATAACGCCGGAACATTAGTGCAGGCAGCTTCCACAGCAATGGCATCCTGGTCATCCAGCGGATAGTTAATGATCAGCCCACTGACGCGTTGCGCGAGAAGATTGTGCACCGCCGCTTTACAGGCTTCGACGCCGCTTCGTTCTACCATCGACACCACCACGCTGGCACCCAGTTGATCGGCGCGAGATTTAATCGCCGCGACAATTTGCGACGGCGCGTGCAGGGCCAGACTGGAGGTGGCAACGCCAATCAGCAACGACTGTTTGCCCGCCAGTTGTTGTGCCACGCGGTTGGGAATGTAATTCAGCTCCGCCATCGCCGCTTCCACTTTTTCCCGCGTTTTCGCAGAAACGTGGCTGGCCTGGTTCACCACGCGGGAAACGGTCTGATAAGAGACACCGGCATACTCTGCGACATCGTATAACGTTACTGGTTTCAT\"\n",
    "trim_dict[\"lacI\"] = 0\n",
    "wild_type_dict[\"Ori\"] = \"TTAATAAGATGATCTTCTTGAGATCGTTTTGGTCTGCGCGTAATCTCTTGCTCTGAAAACGAAAAAACCGCCTTGCAGGGCGGTTTTTCGAAGGTTCTCTGAGCTACCAACTCTTTGAACCGAGGTAACTGGCTTGGAGGAGCGCAGTCACCAAAACTTGTCCTTTCAGTTTAGCCTTAACCGGCGCATGACTTCAAGACTAACTCCTCTAAATCAATTACCAGTGGCTGCTGCCAGTGGTGCTTTTGCATGTCTTTCCGGGTTGGACTCAAGACGATAGTTACCGGATAAGGCGCAGCGGTCGGACTGAACGGGGGGTTCGTGCATACAGTCCAGCTTGGAGCGAACTGCCTACCCGGAACTGAGTGTCAGGCGTGGAATGAGACAAACGCGGCCATAACAGCGGAATGACACCGGTAAACCGAAAGGCAGGAACAGGAGAGCGCACGAGGGAGCCGCCAGGGGGAAACGCCTGGTATCTTTATAGTCCTGTCGGGTTTCGCCACCACTGATTTGAGCGTCAGATTTCGTGATGCTTGTCAGGGGGGCGGAGCCTATGGAAAAACGGCTTTGCCGCGGCCCTCTCACTTCCCTGTTAAGTATCTTCCTGGCATCTTCCAGGAAATCTCCGCCCCGTTCGTAAGCCATTTCCGCTCGCCGCAGTCGAACGACCGAGCGTAGCGAGTCAGTGAGCGAGGAAGCGGAATATATCCTGTATCACATATTCTGCTGACGCACCGGTGCAGCCTTTTTTCTCCTGCCACATGAAGCACTTCACTGACACCCTCATCAGTGCCAACATAGT\"\n",
    "trim_dict[\"Ori\"] = 0\n",
    "wild_type_dict[\"tetA\"] = \"ATGAGTAGCAGTACGAAAATTGCGCTTGTCATCACCCTCCTGGATGCGATGGGGATCGGCTTGATCATGCCGGTACTGCCAACCCTTCTGCGCGAGTTCATTGCAAGCGAAGATATTGCCAACCATTTCGGGGTTCTGCTCGCACTGTACGCCTTAATGCAGGTCATCTTTGCTCCCTGGTTAGGCAAAATGTCAGACAGCTTTGGACGCCGTCCTGTTTTGCTGTTAAGCCTTATCGGAGCGAGCCTGGATTACCTTTTATTGGCCTTCTCCTCGGCACTGTGGATGCTTTATTTGGGTCGTTTGCTGAGTGGGATTACAGGCGCGACGGGTGCCGTGGCGGCGTCGGTGATTGCTGATACGACGTCCGCAAGTCAACGTGTGAAATTGTTCGGCTGGTTAGGAGCCTCCTTTGGCTTGGGCTTAATCGCTGGGCCAATTATTGGCGGGTTCGCCGGCGAAATCTCACCACATTCCCCTTTTTTCATCGCGGCATTACTCAACATTGTCACGTTCCTGGTGGTGATGTTCTGGTTCCGCGAAACGAAAAACACCCGCGATAACACGGATACAGAGGTGGGGGTTGAAACGCAATCGAACAGTGTGTACATCACGCTCTTCAAGACCATGCCCATCCTGCTCATCATCTACTTCTCCGCACAGTTGATTGGGCAAATCCCGGCCACAGTGTGGGTTTTGTTTACGGAAAACCGTTTCGGGTGGAACTCCATGATGGTGGGTTTCTCTCTGGCTGGATTGGGACTTCTGCATAGTGTTTTCCAGGCTTTCGTCGCTGGCCGTATTGCCACAAAGTGGGGAGAAAAAACCGCTGTATTGCTTGGTTTTATCGCAGATAGCTCTGCGTTTGCCTTCTTGGCATTTATTAGCGAAGGCTGGCTCGTGTTTCCGGTATTGATTCTGTTGGCTGGGGGCGGTATCGCATTACCCGCGCTGCAGGGAGTTATGTCTATTCAAACCAAATCACACCAACAAGGAGCGCTGCAAGGCTTACTTGTGTCCCTGACCAACGCAACCGGAGTCATCGGGCCACTTCTGTTCGCTGTAATTTATAACCACTCACTGCCAATTTGGGATGGATGGATCTGGATCATCGGTCTTGCCTTCTACTGCATCATCATTTTGCTGTCAATGACATTCATGCTGACGCCTCAAGCCCAAGGATCTAAACAAGAAACGAGTGCC\"\n",
    "trim_dict[\"tetA\"] = 0\n",
    "wild_type_dict[\"YFP\"] = \"TAACGGCGTAAGGAGGTATTTTTATGGTGTCAAAGGGTGAGGAACTGTTTACGGGGATCGTCCCGATTCTTGTTGAACTTGACGGCGACGTAAATGGTCACAAGTTTTCCGTATCGGGCGAAGGTGAGGGCGATGCGACTTATGGGAAATTAACACTGAAATTCATTTGCACCACCGGAAAACTGCCCGTTCCTTGGCCTACTCTGGTAACCACGTTCGGATATGGTTTACAGTGTTTTGCTCGCTACCCGGACCATATGAAACTGCACGATTTCTTCAAGTCCGCCATGCCGGAGGGCTACGTGCAGGAACGTACAATCTTCTTCAAAGACGATGGTAATTACAAGACCCGTGCTGAAGTTAAATTTGAGGGGGATACTTTAGTCAATCGTATTGAATTGAAGGGGATTGACTTTAAGGAAGACGGTAATATCCTTGGCCACAAGCTTGAATACAACTACAATAGTCACAATGTGTATATTATGGCTGATAAACAGAAGAATGGCATTAAGGTTAACTTTAAGATCCGTCACAATATCGAAGACGGATCTGTCCAGCTTGCTGACCATTATCAGCAAAATACGCCGATCGGTGACGGTCCGGTTTTGTTGCCGGACAACCATTACCTGTCCTATCAGTCGGCGTTAAGTAAAGATCCGAATGAGAAACGCGACCATATGGTTTTGTTGGAGTTTGTGACGGCTGCTGGCATTACGCTTGGGATGGACGAGCTGTATAAATAA\"\n",
    "trim_dict[\"YFP\"] = 0\n",
    "# primers regions is concatentated sequence from the index primer binding sites\n",
    "wild_type_dict[\"primers\"] = \"CATCGGTGAGCCCGGGCTGT\" + \"ACGATGCGTCCGGCGTAGAGG\"\n",
    "trim_dict[\"primers\"] = (20, 21)\n",
    "\n",
    "wild_type_seq = wild_type_dict[region]\n",
    "adapt_len = trim_dict[region]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset no. 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebook_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_bio_dir_1 = notebook_directory[:notebook_directory.find(\"E-Coli\")]\n",
    "pac_bio_dir_1 += \"LacI_CCS_analysis\\\\engineering-bio-lacI-landscape\\\\data_1\\\\processed\\\\targets\"\n",
    "os.chdir(pac_bio_dir_1)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('barcode_1.tsv.gz', 'rb') as f:\n",
    "    bc1_frame_1 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)\n",
    "\n",
    "with gzip.open('barcode_2.tsv.gz', 'rb') as f:\n",
    "    bc2_frame_1 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)\n",
    "    \n",
    "region_file = region + '.tsv.gz'\n",
    "with gzip.open(region_file, 'rb') as f:\n",
    "    region_frame_1 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if region==\"primers\":\n",
    "    adapt_len_f = adapt_len[0]\n",
    "    adapt_len_r = adapt_len[1]\n",
    "else:\n",
    "    adapt_len_f = adapt_len\n",
    "    adapt_len_r = adapt_len\n",
    "    \n",
    "if adapt_len_f>0:\n",
    "    new_seqs = []\n",
    "    for s in region_frame_1[\"seq\"]:\n",
    "        up = [ c.isupper() for c in s ]\n",
    "        if True in up:\n",
    "            n_s = s[up.index(True)-adapt_len_f:-up[::-1].index(True)+adapt_len_r][:350].upper()\n",
    "            if region==\"primers\":\n",
    "                n_s = n_s[:adapt_len_f] + n_s[-adapt_len_r:]\n",
    "            new_seqs.append(n_s)\n",
    "        else:\n",
    "            new_seqs.append(\"\")\n",
    "    region_frame_1[\"seq\"] = new_seqs\n",
    "    region_frame_1 = region_frame_1[region_frame_1[\"seq\"]!=\"\"]\n",
    "    region_frame_1 = region_frame_1[region_frame_1[\"seq\"].str.len()>=adapt_len_f+adapt_len_r]\n",
    "region_frame_1 = region_frame_1[~region_frame_1[\"seq\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset no. 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebook_directory)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pac_bio_dir_2 = notebook_directory[:notebook_directory.find(\"E-Coli\")]\n",
    "pac_bio_dir_2 += \"LacI_CCS_analysis\\\\engineering-bio-lacI-landscape\\\\data_2\\\\processed\\\\targets\"\n",
    "os.chdir(pac_bio_dir_2)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('barcode_1.tsv.gz', 'rb') as f:\n",
    "    bc1_frame_2 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)\n",
    "\n",
    "with gzip.open('barcode_2.tsv.gz', 'rb') as f:\n",
    "    bc2_frame_2 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)\n",
    "    \n",
    "region_file = region + '.tsv.gz'\n",
    "with gzip.open(region_file, 'rb') as f:\n",
    "    region_frame_2 = pd.read_csv(f, sep=\"\\t\", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "if region==\"primers\":\n",
    "    adapt_len_f = adapt_len[0]\n",
    "    adapt_len_r = adapt_len[1]\n",
    "else:\n",
    "    adapt_len_f = adapt_len\n",
    "    adapt_len_r = adapt_len\n",
    "    \n",
    "if adapt_len_f>0:\n",
    "    new_seqs = []\n",
    "    for s in region_frame_2[\"seq\"]:\n",
    "        up = [ c.isupper() for c in s ]\n",
    "        if True in up:\n",
    "            n_s = s[up.index(True)-adapt_len_f:-up[::-1].index(True)+adapt_len_r][:350].upper()\n",
    "            if region==\"primers\":\n",
    "                n_s = n_s[:adapt_len_f] + n_s[-adapt_len_r:]\n",
    "            new_seqs.append(n_s)\n",
    "        else:\n",
    "            new_seqs.append(\"\")\n",
    "    region_frame_2[\"seq\"] = new_seqs\n",
    "    region_frame_2 = region_frame_2[region_frame_2[\"seq\"]!=\"\"]\n",
    "    region_frame_2 = region_frame_2[region_frame_2[\"seq\"].str.len()>=adapt_len_f+adapt_len_r]\n",
    "region_frame_2 = region_frame_2[~region_frame_2[\"seq\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc1_dict = {}\n",
    "for key, value in zip(bc1_frame_1[\"#name\"], bc1_frame_1[\"seq\"]):\n",
    "    bc1_dict[key] = value\n",
    "for key, value in zip(bc1_frame_2[\"#name\"], bc1_frame_2[\"seq\"]):\n",
    "    bc1_dict[key] = value\n",
    "    \n",
    "bc2_dict = {}\n",
    "for key, value in zip(bc2_frame_1[\"#name\"], bc2_frame_1[\"seq\"]):\n",
    "    bc2_dict[key] = value\n",
    "for key, value in zip(bc2_frame_2[\"#name\"], bc2_frame_2[\"seq\"]):\n",
    "    bc2_dict[key] = value\n",
    "    \n",
    "region_dict = {}\n",
    "for key, value in zip(region_frame_1[\"#name\"], region_frame_1[\"seq\"]):\n",
    "    region_dict[key] = value\n",
    "for key, value in zip(region_frame_2[\"#name\"], region_frame_2[\"seq\"]):\n",
    "    region_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_keys = np.unique(np.array(list(bc1_dict.keys()) + list(bc2_dict.keys()) + list(region_dict.keys()) ))\n",
    "len(all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "id_list = []\n",
    "bc2_list = []\n",
    "bc1_list = []\n",
    "seq_list = []\n",
    "\n",
    "for key in all_keys:\n",
    "    if (key in bc1_dict.keys()) & (key in bc2_dict.keys()) & (key in region_dict.keys()):\n",
    "        seq = region_dict[key]\n",
    "        \n",
    "        if type(seq) is str:\n",
    "            id_list.append(key[:-3])\n",
    "            bc1_list.append(bc1_dict[key])\n",
    "            bc2_list.append(bc2_dict[key])\n",
    "            seq_list.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(Seq(wild_type_seq).reverse_complement())[:15])\n",
    "for s in seq_list[:5]:\n",
    "    print(s[:15])\n",
    "print(wild_type_seq[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(Seq(wild_type_seq).reverse_complement())[:15])\n",
    "for s in seq_list[:5]:\n",
    "    print(str(Seq(s).reverse_complement())[:15])\n",
    "print(wild_type_seq[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_list[0][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_frame = pd.DataFrame({\"id\":id_list, \"cterm-bc\":bc2_list, \"nterm-bc\":bc1_list, \"seq\":seq_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pacbio_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_frame[\"seq_length\"] = [ len(x) for x in pacbio_frame[\"seq\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pacbio_frame[\"seq_length\"].mode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pacbio_frame[\"seq_length\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pacbio_frame[\"seq_length\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length_mode = pacbio_frame[\"seq_length\"].mode().values[0]\n",
    "seq_length_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wild_type_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8, 6]\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "bins= [i+0.5 for i in range(seq_length_mode-10, seq_length_mode+10)]\n",
    "\n",
    "axs.hist(pacbio_frame[\"seq_length\"], bins=bins, alpha=0.7, label=region_file);\n",
    "axs.set_yscale('log');\n",
    "axs.set_xticks([i for i in range(seq_length_mode-10, seq_length_mode+10, 2)]);\n",
    "leg = axs.legend(loc='upper right', bbox_to_anchor= (0.97, 0.97), ncol=1, borderaxespad=0)\n",
    "new_length = len(pacbio_frame[pacbio_frame[\"seq_length\"]==seq_length_mode])\n",
    "print(new_length)\n",
    "print(new_length/len(pacbio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_frame = pacbio_frame[pacbio_frame[\"seq_length\"]==seq_length_mode].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_frame = pacbio_frame[~pacbio_frame[\"nterm-bc\"].isnull()]\n",
    "pacbio_frame = pacbio_frame[~pacbio_frame[\"cterm-bc\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pacbio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for_match_num = 0\n",
    "rev_match_num = 0\n",
    "for_barcodeID_list = []\n",
    "rev_barcodeID_list = []\n",
    "for index, row in pacbio_frame.iterrows():\n",
    "    barcode = row[\"nterm-bc\"]\n",
    "    #barcode = barcode[1:-2]\n",
    "    if barcode in for_barcode_clusterID_dict:\n",
    "        for_barcodeID_list.append(for_barcode_clusterID_dict[barcode])\n",
    "        for_match_num += 1\n",
    "    else:\n",
    "        for_barcodeID_list.append(-1)\n",
    "    \n",
    "    barcode = row[\"cterm-bc\"]\n",
    "    #barcode = reverse_complement(barcode[1:-1])\n",
    "    barcode = str(Seq(barcode).reverse_complement())\n",
    "    if barcode in rev_barcode_clusterID_dict:\n",
    "        rev_barcodeID_list.append(rev_barcode_clusterID_dict[barcode])\n",
    "        rev_match_num += 1\n",
    "    else:\n",
    "        rev_barcodeID_list.append(-1)\n",
    "        \n",
    "pacbio_frame[\"for_BC_ID\"] = for_barcodeID_list\n",
    "pacbio_frame[\"rev_BC_ID\"] = rev_barcodeID_list\n",
    "\n",
    "print(for_match_num)\n",
    "print(rev_match_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pacbio_frame) - for_match_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_BC_pairs = []\n",
    "\n",
    "for f_bc, r_bc in zip(pacbio_frame[\"for_BC_ID\"], pacbio_frame[\"rev_BC_ID\"]):\n",
    "    pacbio_BC_pairs.append(f\"{f_bc}_{r_bc}\")\n",
    "\n",
    "pacbio_frame[\"dual_BC_ID\"] = pacbio_BC_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pacbio_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of PacBio reads that have one of the matching barcodes\n",
    "print(len(pacbio_frame[pacbio_frame[\"for_BC_ID\"]!=-1])/len(pacbio_frame))\n",
    "print(len(pacbio_frame[pacbio_frame[\"rev_BC_ID\"]!=-1])/len(pacbio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of PacBio reads that have both matching barcodes\n",
    "print(len(pacbio_frame[(pacbio_frame[\"rev_BC_ID\"]>-1) & (pacbio_frame[\"for_BC_ID\"]>-1)])/len(pacbio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiseq_BC_pairs = hiseq_count_frame[\"dual_BC_ID\"]\n",
    "# fraction of PacBio reads that have dual barcode matching a dual barcode from the HiSeq data\n",
    "print(len(pacbio_frame[pacbio_frame[\"dual_BC_ID\"].isin(hiseq_BC_pairs)])/len(pacbio_frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pacbio_frame[~pacbio_frame[\"dual_BC_ID\"].isin(hiseq_BC_pairs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fraction of HiSeq double barcodes that have matching barcodes in the PacBio dataset\n",
    "hiseq_BC_pairs_series = pd.Series(hiseq_BC_pairs)\n",
    "hiseq_BC_pairs_series_2 = hiseq_BC_pairs_series[hiseq_BC_pairs_series.isin(pacbio_frame[\"dual_BC_ID\"])]\n",
    "print(len(hiseq_BC_pairs_series_2)/len(hiseq_BC_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of HiSeq double barcodes that have matching barcodes in the PacBio dataset\n",
    "print(len(hiseq_BC_pairs_series_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# number of unique dual barcodes found in the PacBio data\n",
    "#    (not necessarily dual barcode pairs that showed up in the HiSeq)\n",
    "print(len(pacbio_frame[pacbio_frame[\"dual_BC_ID\"].str.contains(\"-1\")==False][\"dual_BC_ID\"].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of barcodes in HiSeq dataset\n",
    "len(hiseq_count_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(str1, str2):\n",
    "    if len(str1) != len(str2):\n",
    "        raise ValueError(\"Strand lengths are not equal!\")\n",
    "    else:\n",
    "        count = 0\n",
    "        for (a, b) in zip(str1, str2):\n",
    "            if a!=b:\n",
    "                if ( (a=='X') or (b=='X') ):\n",
    "                    count += 0.5\n",
    "                else:\n",
    "                    count += 1\n",
    "                \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_errors(err_list):\n",
    "    if len(err_list)<=2:\n",
    "        return err_list\n",
    "    else:\n",
    "        #if there are 3 or more terms, throw out outliers\n",
    "        err_list.sort()\n",
    "        #if there are 2 sequences with a low error rate relative to the consensus, assume they are the \"good\" reads.\n",
    "        err_list = [err for err in err_list if err<=err_list[1]]\n",
    "        return err_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Calculate consensus seq for each dual barcode and seq read error rate relative to consensus\n",
    "\n",
    "dual_seq_list = list(pacbio_frame[(pacbio_frame[\"for_BC_ID\"]!=-1) & (pacbio_frame[\"rev_BC_ID\"]!=-1)][\"seq\"].values)\n",
    "\n",
    "dual_concensus_seq_list = []\n",
    "dual_seq_err_rate = []\n",
    "dual_cluster_size_list = []\n",
    "not_same_length_list = []\n",
    "\n",
    "for bc_id in hiseq_count_frame[\"dual_BC_ID\"]:\n",
    "    df = pacbio_frame[pacbio_frame[\"dual_BC_ID\"]==bc_id]\n",
    "    \n",
    "    dual_cluster_size_list.append(len(df))\n",
    "    \n",
    "    seq_list = df[\"seq\"]\n",
    "    \n",
    "    if len(seq_list)>1:\n",
    "        same_length = True\n",
    "        for x, y in zip(seq_list[1:], seq_list[:-1]):\n",
    "            same_length = same_length and (len(x) == len(y))\n",
    "            \n",
    "        if same_length:\n",
    "            alignment = MultipleSeqAlignment([ SeqRecord(Seq(x)) for x in seq_list ])\n",
    "            summary_align = AlignInfo.SummaryInfo(alignment)\n",
    "            concensus_seq = str(summary_align.dumb_consensus(threshold=0.2, consensus_alpha=generic_dna))\n",
    "\n",
    "            dual_concensus_seq_list.append(concensus_seq)\n",
    "            errors = []\n",
    "            for c in seq_list:\n",
    "                errors.append(distance(c, concensus_seq))\n",
    "            errors = trim_errors(errors)\n",
    "            dual_seq_err_rate.append(sum(errors))\n",
    "        else:\n",
    "            not_same_length_list.append(df)\n",
    "            dual_concensus_seq_list.append(\"\")\n",
    "            dual_seq_err_rate.append(0)\n",
    "    else:\n",
    "        if len(seq_list)==1:\n",
    "            dual_concensus_seq_list.append(seq_list.iloc[0])\n",
    "        else:\n",
    "            dual_concensus_seq_list.append(\"\")\n",
    "        dual_seq_err_rate.append(0)\n",
    "    \n",
    "hiseq_count_frame[\"concensus_seq\"] = dual_concensus_seq_list\n",
    "hiseq_count_frame[\"seq_error_rate\"] = dual_seq_err_rate\n",
    "hiseq_count_frame[\"pacbio_seq_count\"] = dual_cluster_size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(not_same_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dual_concensus_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hiseq_count_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8, 6]\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "bins= [i-0.5 for i in range(20)]\n",
    "axs.hist(hiseq_count_frame[\"pacbio_seq_count\"], bins=bins);\n",
    "axs.set_yscale(\"log\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Calculate mutation rate of consensus seq relative to wild type seq\n",
    "\n",
    "concensus_mutation_rate_list = []\n",
    "\n",
    "hiseq_count_frame[\"concensus_seq\"] = hiseq_count_frame[\"concensus_seq\"].str.replace(\"X\", \"N\")\n",
    "\n",
    "for index, row in hiseq_count_frame.iterrows():\n",
    "    consensus_seq = row[\"concensus_seq\"]\n",
    "    if consensus_seq!=\"\":\n",
    "        errors = fitness.hamming_distance(consensus_seq, wild_type_seq, IGNORE_N=True)\n",
    "        \n",
    "        concensus_mutation_rate_list.append(errors)\n",
    "    \n",
    "    else:\n",
    "        concensus_mutation_rate_list.append(-1)\n",
    "    \n",
    "hiseq_count_frame[\"concensus_seq_mutations\"] = concensus_mutation_rate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [8, 6]\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "bins= [i-0.5 for i in range(20)]\n",
    "axs.hist(hiseq_count_frame[\"concensus_seq_mutations\"], bins=bins, label=\">0 PacBio Reads\");\n",
    "\n",
    "df = hiseq_count_frame[hiseq_count_frame[\"pacbio_seq_count\"]>10]\n",
    "axs.hist(df[\"concensus_seq_mutations\"], bins=bins, label=\">10 PacBio Reads\");\n",
    "df = hiseq_count_frame[hiseq_count_frame[\"pacbio_seq_count\"]>30]\n",
    "axs.hist(df[\"concensus_seq_mutations\"], bins=bins, label=\">30 PacBio Reads\");\n",
    "\n",
    "axs.set_yscale(\"log\");\n",
    "axs.set_ylabel(\"Count\")\n",
    "axs.set_xlabel(region + \" Mutations\")\n",
    "leg = axs.legend(loc='upper right', bbox_to_anchor= (0.97, 0.97), ncol=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame[hiseq_count_frame[\"pacbio_seq_count\"]>2]\n",
    "df = df[df[\"concensus_seq_mutations\"]>0]\n",
    "print(len(df))\n",
    "df = df[df[\"concensus_seq_mutations\"]>1]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame\n",
    "df = df[df[\"RS_name\"]!=\"\"]\n",
    "df[[\"dual_BC_ID\", \"RS_name\", \"concensus_seq_mutations\", \"pacbio_seq_count\", \"seq_error_rate\", \"concensus_seq\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pacbio_frame[pacbio_frame[\"dual_BC_ID\"]==\"31486_25239\"]\n",
    "df[[\"seq\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pacbio_region_count = hiseq_count_frame[\"pacbio_seq_count\"]\n",
    "pacbio_region_mutations = hiseq_count_frame[\"concensus_seq_mutations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pause here-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(notebook_directory)\n",
    "pickle_file = experiment + '_BarSeqFitnessFrame.pkl'\n",
    "print(pickle_file)\n",
    "\n",
    "barcode_frame = pickle.load(open(pickle_file, 'rb'))\n",
    "\n",
    "barcode_frame.barcode_frame[\"pacbio_\" + region + \"_count\"] = pacbio_region_count\n",
    "barcode_frame.barcode_frame[\"pacbio_\" + region + \"_mutations\"] = pacbio_region_mutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = barcode_frame.barcode_frame\n",
    "warning_list = []\n",
    "for mut, n in zip(df[\"pacbio_\" + region + \"_mutations\"], df[\"pacbio_\" + region + \"_count\"]):\n",
    "    w = (n>0) and (mut>0)\n",
    "    warning_list.append(w)\n",
    "warning_list = np.array(warning_list)\n",
    "len(warning_list[warning_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wild_type_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_frame.save_as_pickle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Look at distributions of fitness values - to see if there is an effect from mutations to the sequence region\n",
    "\n",
    "fitness_0_list = []\n",
    "fitness_20_list = []\n",
    "fitness_0_0_list = []\n",
    "fitness_20_0_list = []\n",
    "df = barcode_frame.barcode_frame\n",
    "df = df[df[\"total_counts\"]>3000]\n",
    "\n",
    "for fit_0_b, fit_20_b in zip(df[\"fitness_0_estimate_b\"], df[\"fitness_20_estimate_b\"]):\n",
    "    fitness_0_list += list(fit_0_b)\n",
    "    fitness_0_0_list += list(fit_0_b)[:1]\n",
    "    fitness_20_list += list(fit_20_b)\n",
    "    fitness_20_0_list += list(fit_20_b)[:1]\n",
    "    \n",
    "fitness_0_list = np.array(fitness_0_list)\n",
    "fitness_20_list = np.array(fitness_20_list)\n",
    "fitness_0_0_list = np.array(fitness_0_0_list)\n",
    "fitness_20_0_list = np.array(fitness_20_0_list)\n",
    "fitness_diff_list = fitness_20_list - fitness_0_list\n",
    "normed_diff_list = (fitness_20_list - fitness_0_list)/fitness_0_list\n",
    "fitness_diff_0_list = fitness_20_0_list - fitness_0_0_list\n",
    "normed_diff_0_list = (fitness_20_0_list - fitness_0_0_list)/fitness_0_0_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Look at distributions of fitness values - to see if there is an effect from mutations to the sequence region\n",
    "\n",
    "fitness_0_region = []\n",
    "fitness_20_region = []\n",
    "fitness_0_0_region = []\n",
    "fitness_20_0_region = []\n",
    "df = barcode_frame.barcode_frame\n",
    "df = df[warning_list]\n",
    "df = df[df[\"total_counts\"]>3000]\n",
    "\n",
    "for fit_0_b, fit_20_b in zip(df[\"fitness_0_estimate_b\"], df[\"fitness_20_estimate_b\"]):\n",
    "    fitness_0_region += list(fit_0_b)\n",
    "    fitness_0_0_region += list(fit_0_b)[:1]\n",
    "    fitness_20_region += list(fit_20_b)\n",
    "    fitness_20_0_region += list(fit_20_b)[:1]\n",
    "    \n",
    "fitness_0_region = np.array(fitness_0_region)\n",
    "fitness_20_region = np.array(fitness_20_region)\n",
    "fitness_0_0_region = np.array(fitness_0_0_region)\n",
    "fitness_20_0_region = np.array(fitness_20_0_region)\n",
    "fitness_diff_region = fitness_20_region - fitness_0_region\n",
    "normed_diff_region = (fitness_20_region - fitness_0_region)/fitness_0_region\n",
    "fitness_diff_0_region = fitness_20_0_region - fitness_0_0_region\n",
    "normed_diff_0_region = (fitness_20_0_region - fitness_0_0_region)/fitness_0_0_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [6, 4]\n",
    "fig, axs = plt.subplots(1, 1)\n",
    "bins= [i-0.5 for i in range(20)]\n",
    "axs.hist(hiseq_count_frame[\"concensus_seq_mutations\"], bins=bins, label=\">0 PacBio Reads\");\n",
    "\n",
    "df = hiseq_count_frame[hiseq_count_frame[\"pacbio_seq_count\"]>10]\n",
    "axs.hist(df[\"concensus_seq_mutations\"], bins=bins, label=\">10 PacBio Reads\");\n",
    "df = hiseq_count_frame[hiseq_count_frame[\"pacbio_seq_count\"]>30]\n",
    "axs.hist(df[\"concensus_seq_mutations\"], bins=bins, label=\">30 PacBio Reads\");\n",
    "\n",
    "axs.set_yscale(\"log\");\n",
    "axs.set_ylabel(\"Count\")\n",
    "axs.set_xlabel(region + \" Mutations\")\n",
    "leg = axs.legend(loc='upper right', bbox_to_anchor= (0.97, 0.97), ncol=1)\n",
    "\n",
    "# Look at distributions of fitness values - to see if there is an effect from mutations to the sequence region\n",
    "plt.rcParams[\"figure.figsize\"] = [16, 12]\n",
    "fig, axs_grid = plt.subplots(3, 3)\n",
    "fig.suptitle(region + \" fitness count ratios\", y=0.98, size=24)\n",
    "axs = axs_grid.flatten()\n",
    "\n",
    "axs[0].get_shared_y_axes().join(*axs[:3]);\n",
    "\n",
    "shift = 0.025\n",
    "for i, (ax_0, ax_1, ax_2) in enumerate(zip(axs[:3], axs[3:6], axs[6:])):\n",
    "    ax_0.get_shared_x_axes().join(ax_0, ax_1, ax_2);\n",
    "    for ax in [ax_0, ax_1, ax_2]:\n",
    "        box = ax.get_position()\n",
    "        box.x0 = box.x0 + shift*i\n",
    "        box.x1 = box.x1 + shift*i\n",
    "        ax.set_position(box)\n",
    "\n",
    "lists_to_plot = [fitness_0_list, fitness_20_list, normed_diff_list]\n",
    "lists_to_plot_0 = [fitness_0_0_list, fitness_20_0_list, normed_diff_0_list]\n",
    "regions_to_plot = [fitness_0_region, fitness_20_region, normed_diff_region]\n",
    "regions_to_plot_0 = [fitness_0_0_region, fitness_20_0_region, normed_diff_0_region]\n",
    "names = [\"Fitness without Tet\", \"Fitness with Tet\", \"Normalized Difference\"]\n",
    "\n",
    "color_list = sns.color_palette()\n",
    "\n",
    "for ax_0, ax_1, ax_2, data, data_0, reg_data, reg_data_0, name in zip(axs[:3], axs[3:6], axs[6:], lists_to_plot,\n",
    "                                                                      lists_to_plot_0, regions_to_plot, regions_to_plot_0,\n",
    "                                                                      names):\n",
    "    bins = 31\n",
    "    ax_0.set_ylabel(\"Count Ratio with Full Library\")\n",
    "    ax_1.set_ylabel(\"[IPTG]=0 Count\")\n",
    "    ax_2.set_ylabel(\"All [IPTG] Count\")\n",
    "    alpha=1\n",
    "    \n",
    "    if name==\"Fitness without Tet\":\n",
    "        bins = np.linspace(0.4,1.3,bins)\n",
    "    if name==\"Fitness with Tet\":\n",
    "        bins = np.linspace(-0.7,1.3,bins)\n",
    "    if name==\"Fitness Difference\":\n",
    "        bins = np.linspace(-1.7,0.5,bins)\n",
    "    if name==\"Normalized Difference\":\n",
    "        bins = np.linspace(-1.7,0.5,bins)\n",
    "        \n",
    "    n_all, b, p = ax_2.hist(data, bins=bins, label=\"Full Library\", color=color_list[1])\n",
    "    n_0, b, p = ax_1.hist(data_0, bins=bins, label=\"Full Library\", color=color_list[0])\n",
    "    reg_n_all, b, p = ax_2.hist(reg_data, bins=bins, label=\"Mutated \" + region, color=\"lightgray\", alpha=0.85)\n",
    "    reg_n_0, b, p = ax_1.hist(reg_data_0, bins=bins, label=\"Mutated \" + region, color=\"lightgray\", alpha=0.85)\n",
    "    \n",
    "    x = (bins[:-1] + bins[1:])/2\n",
    "    \n",
    "    y = reg_n_all/n_all\n",
    "    yerr = np.sqrt(y/n_all*(1+y))\n",
    "    ax_0.errorbar(x, y, yerr, fmt=\"o\", alpha=alpha, label=\"All [IPTG]\", color=color_list[1]);\n",
    "    \n",
    "    y = reg_n_0/n_0\n",
    "    yerr = np.sqrt(y/n_0*(1+y))\n",
    "    ax_0.errorbar(x, y, yerr, fmt=\"o\", alpha=alpha, label=\"[IPTG] = 0\", color=color_list[0]);\n",
    "    ax_0.set_yscale(\"log\");\n",
    "    ax_1.set_yscale(\"log\");\n",
    "    ax_2.set_yscale(\"log\");\n",
    "    ax_2.set_xlabel(name)\n",
    "leg = axs[0].legend(loc='lower left', bbox_to_anchor= (0.03, 1.03), ncol=1, borderaxespad=0, frameon=True, fontsize=12)\n",
    "leg.get_frame().set_edgecolor('k');\n",
    "for ax in [axs[3], axs[6]]:\n",
    "    leg = ax.legend(loc='upper left', bbox_to_anchor= (0.03, 0.97), ncol=1, borderaxespad=0, frameon=True, fontsize=12)\n",
    "    leg.get_frame().set_edgecolor('k');\n",
    "\n",
    "df = barcode_frame.barcode_frame\n",
    "df_w = df[warning_list]\n",
    "df = df[df[\"total_counts\"]>3000]\n",
    "df_w = df_w[df_w[\"total_counts\"]>3000]\n",
    "total_ratio = len(df_w)/len(df)\n",
    "axs[0].set_ylim(total_ratio/10, total_ratio*10)\n",
    "for ax in axs[:3]:\n",
    "    xlim = ax.get_xlim()\n",
    "    ax.plot(xlim, [total_ratio]*2, \"--k\")\n",
    "    ax.set_xlim(xlim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at distributuion and location of mutations - to see if there are any paterns\n",
    "\n",
    "# For each variant, create list of DNA changes from wild-type sequence\n",
    "df = barcode_frame.barcode_frame\n",
    "dna_list = list(hiseq_count_frame[\"concensus_seq\"])\n",
    "dna_distance = list(df[\"pacbio_\" + region + \"_mutations\"])\n",
    "\n",
    "mutations_lists = []\n",
    "position_lists = []\n",
    "\n",
    "for seq, dist in zip(dna_list, dna_distance):\n",
    "    mutations = []\n",
    "    positions = []\n",
    "    if (dist>0):\n",
    "        for ind, (c1, c2) in enumerate(zip(seq, wild_type_seq)): \n",
    "            if (c1 != c2) and (c1 != 'N'):\n",
    "                mutations.append(f\"{c2}{ind+1}{c1}\")\n",
    "                positions.append(ind+1)\n",
    "    mutations_lists.append(mutations)\n",
    "    position_lists.append(positions)\n",
    "    \n",
    "hiseq_count_frame[region + \"_mutation_codes\"] = mutations_lists\n",
    "hiseq_count_frame[region + \"_mutation_positions\"] = position_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame\n",
    "df = df[df[\"concensus_seq_mutations\"]>=1]\n",
    "df = df[df[\"concensus_seq_mutations\"]<5]\n",
    "\n",
    "df_rand = hiseq_count_frame.sample(len(df))\n",
    "\n",
    "for param, lab in zip([\"Low Level\", \"High Level\", \"IC50\"], [\"$G_0$\", \"$G_{âˆž}$\", \"$EC_{50}$\"]):\n",
    "    log_low = df[param]\n",
    "    log_low_rand = df_rand[param]\n",
    "    positions = df[region + \"_mutation_positions\"]\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    y_rand_list = []\n",
    "\n",
    "    for y, p_list, y_rand in zip(log_low, positions, log_low_rand):\n",
    "        for p in p_list:\n",
    "            x_list.append(p)\n",
    "            y_list.append(y)\n",
    "            y_rand_list.append(y_rand)\n",
    "    x_list = np.array(x_list)\n",
    "    y_list = np.array(y_list)\n",
    "    y_rand_list = np.array(y_rand_list)\n",
    "    x_av = np.unique(x_list)\n",
    "    y_av = [np.mean(y_list[x_list==x]) for x in x_av]\n",
    "    y_r_av = [np.mean(y_rand_list[x_list==x]) for x in x_av]\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = [16,5]\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].get_shared_y_axes().join(*axs);\n",
    "\n",
    "    axs[0].plot(x_list, y_list, \"o\", alpha=0.2);\n",
    "    axs[0].set_title(f\"variants with {region} mutations\", size=20)\n",
    "    axs[1].plot(x_list, y_rand_list, \"o\", alpha=0.2);\n",
    "    axs[1].set_title(\"randomly selected variants\", size=20)\n",
    "    for ax in axs:\n",
    "        ax.set_yscale(\"log\");\n",
    "        ax.set_xlabel(f\"Position of Mutation in {region} sequence\")\n",
    "        ax.set_ylabel(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wild_type_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame\n",
    "df = df[df[\"concensus_seq_mutations\"]>=1]\n",
    "df = df[df[\"concensus_seq_mutations\"]<5]\n",
    "\n",
    "df_rand = hiseq_count_frame.sample(len(df))\n",
    "\n",
    "fitness = [x[0] for x in df[\"fitness_20_estimate_b\"] ]\n",
    "fitness_rand = [x[0] for x in df_rand[\"fitness_20_estimate_b\"] ]\n",
    "positions = df[region + \"_mutation_positions\"]\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "y_rand_list = []\n",
    "\n",
    "for y, p_list, y_rand in zip(fitness, positions, fitness_rand):\n",
    "    for p in p_list:\n",
    "        x_list.append(p)\n",
    "        y_list.append(y)\n",
    "        y_rand_list.append(y_rand)\n",
    "x_list = np.array(x_list)\n",
    "y_list = np.array(y_list)\n",
    "y_rand_list = np.array(y_rand_list)\n",
    "x_av = np.unique(x_list)\n",
    "y_av = [np.mean(y_list[x_list==x]) for x in x_av]\n",
    "y_r_av = [np.mean(y_rand_list[x_list==x]) for x in x_av]\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = [16,5]\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(x_list, y_list, \"o\", alpha=0.3);\n",
    "axs[0].set_title(f\"variants with {region} mutations\", size=20)\n",
    "print(np.mean(y_list))\n",
    "axs[1].plot(x_list, y_rand_list, \"o\", alpha=0.3);\n",
    "axs[1].set_title(\"randomly selected variants\", size=20)\n",
    "print(np.mean(y_rand_list))\n",
    "for ax in axs:\n",
    "    #ax.set_yscale(\"log\");\n",
    "    ax.set_xlabel(f\"Position of Mutation in {region} sequence\")\n",
    "    ax.set_ylabel(\"Fitness with tet and [IPTG]=0\")\n",
    "ylim = axs[0].get_ylim()\n",
    "axs[1].set_ylim(ylim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame\n",
    "df = df[df[\"concensus_seq_mutations\"]>=1]\n",
    "df = df[df[\"concensus_seq_mutations\"]<5]\n",
    "\n",
    "df_rand = hiseq_count_frame.sample(len(df))\n",
    "\n",
    "fitness = [x[-1] for x in df[\"fitness_20_estimate_b\"] ]\n",
    "fitness_rand = [x[-1] for x in df_rand[\"fitness_20_estimate_b\"] ]\n",
    "positions = df[region + \"_mutation_positions\"]\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "y_rand_list = []\n",
    "\n",
    "for y, p_list, y_rand in zip(fitness, positions, fitness_rand):\n",
    "    for p in p_list:\n",
    "        x_list.append(p)\n",
    "        y_list.append(y)\n",
    "        y_rand_list.append(y_rand)\n",
    "x_list = np.array(x_list)\n",
    "y_list = np.array(y_list)\n",
    "y_rand_list = np.array(y_rand_list)\n",
    "x_av = np.unique(x_list)\n",
    "y_av = [np.mean(y_list[x_list==x]) for x in x_av]\n",
    "y_r_av = [np.mean(y_rand_list[x_list==x]) for x in x_av]\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = [16,5]\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(x_list, y_list, \"o\", alpha=0.3);\n",
    "axs[0].set_title(f\"variants with {region} mutations\", size=20)\n",
    "print(np.mean(y_list))\n",
    "axs[1].plot(x_list, y_rand_list, \"o\", alpha=0.3);\n",
    "axs[1].set_title(\"randomly selected variants\", size=20)\n",
    "print(np.mean(y_rand_list))\n",
    "for ax in axs:\n",
    "    #ax.set_yscale(\"log\");\n",
    "    ax.set_xlabel(f\"Position of Mutation in {region} sequence\")\n",
    "    ax.set_ylabel(\"Fitness with tet and [IPTG]=2048\")\n",
    "ylim = axs[0].get_ylim()\n",
    "axs[1].set_ylim(ylim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hiseq_count_frame\n",
    "df = df[df[\"concensus_seq_mutations\"]>=1]\n",
    "df = df[df[\"concensus_seq_mutations\"]<5]\n",
    "\n",
    "df_rand = hiseq_count_frame.sample(len(df))\n",
    "\n",
    "fitness = [x[0] for x in df[\"fitness_0_estimate_b\"] ]\n",
    "fitness_rand = [x[0] for x in df_rand[\"fitness_0_estimate_b\"] ]\n",
    "positions = df[region + \"_mutation_positions\"]\n",
    "\n",
    "x_list = []\n",
    "y_list = []\n",
    "y_rand_list = []\n",
    "\n",
    "for y, p_list, y_rand in zip(fitness, positions, fitness_rand):\n",
    "    for p in p_list:\n",
    "        x_list.append(p)\n",
    "        y_list.append(y)\n",
    "        y_rand_list.append(y_rand)\n",
    "x_list = np.array(x_list)\n",
    "y_list = np.array(y_list)\n",
    "y_rand_list = np.array(y_rand_list)\n",
    "x_av = np.unique(x_list)\n",
    "y_av = [np.mean(y_list[x_list==x]) for x in x_av]\n",
    "y_r_av = [np.mean(y_rand_list[x_list==x]) for x in x_av]\n",
    "        \n",
    "plt.rcParams[\"figure.figsize\"] = [16,5]\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "axs[0].plot(x_list, y_list, \"o\", alpha=0.2);\n",
    "axs[0].set_title(f\"variants with {region} mutations\", size=20)\n",
    "print(np.mean(y_list))\n",
    "axs[1].plot(x_list, y_rand_list, \"o\", alpha=0.2);\n",
    "axs[1].set_title(\"randomly selected variants\", size=20)\n",
    "print(np.mean(y_rand_list))\n",
    "for ax in axs:\n",
    "    #ax.set_yscale(\"log\");\n",
    "    ax.set_xlabel(f\"Position of Mutation in {region} sequence\")\n",
    "    ax.set_ylabel(\"Fitness without tet and [IPTG]=0\")\n",
    "ylim = axs[0].get_ylim()\n",
    "axs[1].set_ylim(ylim);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_frame = hiseq_count_frame[[\"dual_BC_ID\", \"pacbio_seq_count\", \"concensus_seq\", \"concensus_seq_mutations\",\n",
    "                               region + \"_mutation_codes\", region + \"_mutation_positions\"]].copy()\n",
    "\n",
    "out_frame.rename(columns={\"concensus_seq\": \"concensus_\"+region+\"_seq\", \"concensus_seq_mutations\": region+\"_mutations\"},\n",
    "                 inplace=True)\n",
    "\n",
    "out_file = region + \"_pacbio_frame.pkl\"\n",
    "\n",
    "with open(out_file, 'wb') as f:\n",
    "    pickle.dump(out_frame, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
